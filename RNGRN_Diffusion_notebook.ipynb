{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29818572",
   "metadata": {},
   "source": [
    "# 0. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a19b0b8",
   "metadata": {},
   "source": [
    "## Overview "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cab1db3",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "This notebook establishes the **Recurrent Neural Gene Regulatory Networks (RNGRNs)**. The RNGRN system takes inspiration from the Recurrent Neural Chemical Reaction Networks (RNCRNs) work by Alex Dack (https://arxiv.org/abs/2406.03456). \n",
    "\n",
    "This system seeks to use gene regulatory network modelling to replicate the spatiotemporal dynamics of Turing pattern formation. Here, we seek to use **Hill functions** of gene activation as a surrogate for **sigmoid activation functions**. This confers our gene regulatory network neural net-like properties, allowing it to 'learn' the spatiotemporal Turing pattern formation of a given target system.\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"Images/Hill.png\" alt=\"Hill\" width=\"60%\">\n",
    "</div>\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d947c05",
   "metadata": {},
   "source": [
    "## Background"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6390d8",
   "metadata": {},
   "source": [
    "### Biological patterning\n",
    "\n",
    "Biological patterning is a majorly unsolved area in biology. Patterning is observed across all scales of life, from microbiology, developmental biology and ecology. \n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"Images/Angelfish.png\" alt=\"Angelfish\" width=\"50%\">\n",
    "</div>\n",
    "\n",
    "In developmental biology, biological patterns are fundamental in the correct formation of body plans, such as the segmentation of our backbones.\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"Images/Embryo.png\" alt=\"Embryo\" width=\"50%\">\n",
    "</div>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c8ed4f",
   "metadata": {},
   "source": [
    "### Reaction-Diffusion models\n",
    "\n",
    "The most widely-accepted mathematical models of biological patterning are reaction-diffusion (RD) models, proposed by Alan Turing in 1952. \n",
    "\n",
    "These RD models are coupled systems of PDEs that describe the interaction between two or more chemical species that can diffuse. For 2 chemical species: \n",
    "\n",
    "$$\n",
    "\\frac{\\partial u}{\\partial t} = f(u,v) + D_u \\nabla^2 u,\\qquad\n",
    "\\frac{\\partial v}{\\partial t} = g(u,v) + D_v \\nabla^2 v,\n",
    "$$\n",
    "\n",
    "* $u(\\mathbf{x},t)$ and $v(\\mathbf{x},t)$ are concentrations of two interacting species, termed morphogens.\n",
    "\n",
    "* $f,g$ describe the interactions between morphogens\n",
    "\n",
    "* $D_u, D_v$ are diffusion coefficients\n",
    "\n",
    "* The Laplacian term $\\nabla^2$ models spatial spreading.\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1c0e4e",
   "metadata": {},
   "source": [
    "### Turing patterns\n",
    "\n",
    "When this diffusion becomes unstable, \"Turing patterns\" can form and these patterns can be fitted to real-world biology. \n",
    "\n",
    "There are two criteria for Turing pattern formation in RD models:\n",
    "\n",
    "1. Stable steady state in well-mixed conditions \n",
    "\n",
    "    If the system was well-mixed, where no diffusion is occuring, then we would have an ODE system:\n",
    "\n",
    "    $$\n",
    "    \\dot u = f(u,v),\\qquad \\dot v = g(u,v).\n",
    "    $$\n",
    "\n",
    "    When at steady state: \n",
    "\n",
    "    $$(u^*, v^*) \\text{ satisfies } f(u^*, v^*) = 0 \\quad \\text{and} \\quad g(u^*, v^*) = 0$$\n",
    "\n",
    "    Introducing a small perturbation:\n",
    "\n",
    "    $$u(t) = u^* + \\delta u(t),\\quad v(t) = v^* + \\delta v(t),\\quad \\delta(t) = \\begin{pmatrix} \\delta u(t) \\\\ \\delta v(t) \\end{pmatrix}$$\n",
    "\n",
    "    Linear stability analysis around $(u^*, v^*)$: \n",
    "    $$\\frac{d\\delta}{dt} = J \\delta,\\quad J = \\begin{pmatrix} f_u & f_v \\\\ g_u & g_v \\end{pmatrix}_{(u^*, v^*)}$$\n",
    "\n",
    "    The steady state must be stable: \n",
    "\n",
    "    $\\Re(\\lambda_i(J)) < 0$ for all eigenvalues $\\lambda_i$.\n",
    "\n",
    "    This is true when: \n",
    "\n",
    "    $$\n",
    "    \\mathrm{tr}(J) < 0,\\qquad \\det(J) > 0.\n",
    "    $$\n",
    "\n",
    "    When well-mixed, the steady states are stable means the system returns to its original state:\n",
    "    $$\\lim_{t \\to \\infty} \\|\\delta(t)\\| = 0,\\quad (u(t), v(t)) \\to (u^*, v^*).$$\n",
    "\n",
    "2. Diffusion-driven instability\n",
    "    \n",
    "    When diffusion is present, i.e. we use the PDE system:  \n",
    "\n",
    "    $$\n",
    "    \\frac{\\partial u}{\\partial t} = f(u,v) + D_u \\nabla^2 u,\\qquad\n",
    "    \\frac{\\partial v}{\\partial t} = g(u,v) + D_v \\nabla^2 v,\n",
    "    $$\n",
    "\n",
    "    Again, we introduce a small perturbation and use Linear stability analysis - giving the same Jacobian:\n",
    "\n",
    "    $$J = \\begin{pmatrix} f_u & f_v \\\\ g_u & g_v \\end{pmatrix}_{(u^*, v^*)}$$\n",
    "\n",
    "    But now, we also have a Diagonal diffusion matrix:\n",
    "    \n",
    "    $$\\quad D = \\begin{pmatrix} D_u & 0 \\\\ 0 & D_v \\end{pmatrix}$$\n",
    "\n",
    "    Considering perturbations with spatial frequency \\(k\\) (Fourier modes), the spatiotemporal dynamics are governed by the matrix:\n",
    "\n",
    "    $$\n",
    "    J - k^2 D.\n",
    "    $$\n",
    "\n",
    "    If, for some nonzero \\(k\\), this matrix has an eigenvalue with positive real part, then the system will be unstable with diffusion. This is true when: \n",
    "\n",
    "    $$\n",
    "    D_u g_v + D_v f_u > 0,\n",
    "    $$\n",
    "\n",
    "    and\n",
    "\n",
    "    $$\n",
    "    (D_u g_v + D_v f_u)^2 > 4 D_u D_v \\det(J).\n",
    "    $$\n",
    "\n",
    "    This means that the diffusion-driven instability will amplify noise at the characteristic wavelength ( \\(k\\) with max positive eigenvalue/growth rate) to produce a pattern at a specific wavelength: \n",
    "\n",
    "    $$\n",
    "    \\lambda_{\\text{pattern}} \\approx \\frac{2\\pi}{k_{\\max}}.\n",
    "    $$\n",
    "\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"Images/Kondor4.png\" alt=\"Kondor4\" width=\"70%\">\n",
    "</div>\n",
    "\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b597eb7a",
   "metadata": {},
   "source": [
    "### Activator-inhibitor models\n",
    "\n",
    "Intuitively, reactions create local amplification (short-range activation), while diffusion produces long range suppression. When these effects are balanced appropriately, this produces Turing patterns of spots, stripes, or labyrinths.\n",
    "\n",
    "\n",
    "Key characteristics of Turing patterns:\n",
    "- Spontaneously forming (in noise)\n",
    "- Self-repairing\n",
    "- Sensitive to model parameters - reaction and diffusion\n",
    "- Sensitive to domain and boundary conditions\n",
    "\n",
    "A common form of RD models that produce Turing patterns are the activator-inhibitor models by Gierer and Meinhardt (1972), which describes a slow diffusing activator and a fast diffusing inhibitor. \n",
    "- Small noise in the activator leads to positive feedback and peaks of activation. \n",
    "- These peaks of activation induce inhibitor production.\n",
    "- The inhibitor diffuses quickly, leading to zones of inhibition surrounding the peaks of activation. Activator diffuses slowly and is suppressed by the inhibitor.\n",
    "- Peaks of activation spaced out by a minimum distance. \n",
    "- Creates pattern of finite wavelength.\n",
    "\n",
    "\n",
    "<div style=\"display: flex; justify-content: center; align-items: center;\">\n",
    "    <img src=\"Images/Gierer.png\" alt=\"Gierer\" style=\"width: 30%; margin-right: 10px;\">\n",
    "    <img src=\"Images/Formation.png\" alt=\"Formation\" style=\"width: 30%;\">\n",
    "</div>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020371df",
   "metadata": {},
   "source": [
    "### Turing patterns in-vitro and in-vivo\n",
    "\n",
    "Moving from theory to reality, there have been very few instances where these models have been recreated in the lab. Because of the simplicity of these models, they are highly senstitive their parameterisation. Most importantly, they require a large difference in diffusion coefficient between the morphogens. This parameter sensitivity does not pair well with the noise of biological systems.\n",
    "\n",
    "Here, this study by Mark Isalan's lab shows the 'Turing volume' of a RD model. This refers to the parameter space (of 3 params here that make up the 3 axes) that satisfies the Turing pattern criteria above. When the differential diffusivity (D) between the 2 morphogens is 0.01 (100-fold difference in diffusion coefficient) the Turing volume is already small. However when the differential diffusivity is changed to 0.1 (10-fold difference in diffusion coefficient), this Turing volume becomes tiny, demonstrating the importance of differential diffusivity in Turing pattern formation.\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"Images/Diambra.png\" alt=\"Diambra\" width=\"30%\">\n",
    "</div>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cb92e9",
   "metadata": {},
   "source": [
    "### Increasing the robustness of Turing patterns\n",
    "\n",
    "Recent works by the Isalan and Endres groups have shown that larger RD models, composed of more than 2 morphogens are more robust. \n",
    "They identified the most robust 3-node network (Scholes 2019), and implemented it in-vitro, as the first example of an in-vitro Turing pattern.\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"Images/Tica.png\" alt=\"Tica\" width=\"30%\">\n",
    "</div>\n",
    "\n",
    "However, even this model is only theoretically capable of Turing patterns in 0.022% of parameter combinations.\n",
    "\n",
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0996a39e",
   "metadata": {},
   "source": [
    "### The inverse Turing problem\n",
    "\n",
    "**The goal of this work is to discover new RD models that produce any biological pattern that we desire. The RNGRN system is a neural network that has an architecture inspired by gene regulatory networks (GRN), thus the idea is that given any biological pattern, can we predict a GRN, and its associated parameters, that would produce this specific pattern?**\n",
    "\n",
    "**Furthermore, we are interested in knowing the Turing robustness of these predicted GRNs - and can this robustness be improved??**\n",
    "\n",
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592754bd",
   "metadata": {},
   "source": [
    "## RNGRN system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfba9b57",
   "metadata": {},
   "source": [
    "### Central dogma\n",
    "Consider a conventional gene. It codes for a specific gene product (usually a protein) and the production of this gene product (AKA gene expression) is under tight control. Specific transcripton factors will bind to the enhancer or operator of this gene to upregulate or downregulate gene expression. There will be 'noisy/stochastic' basal gene expression - baseline gene expression level that occurs irrespective of the gene's regulation. \n",
    "\n",
    "****\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69666a22",
   "metadata": {},
   "source": [
    "### Gene regulatory networks\n",
    "Taking a systems biology perspective here, gene regulatory networks arise when a set of genes regulate each other's gene expression. One such form of network can arise when the gene product of one gene is a transcription factor that can bind to the upstream region of another gene in the network to influence its gene expression.\n",
    "\n",
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e6bebf",
   "metadata": {},
   "source": [
    "### Background Concept of RNGRNs\n",
    "\n",
    "This work is based on Alex Dack's RNCRNs (the chemical reaction network equivalent of RNGRNs). Here, he sought to develop a framework that allows for the design of DNA-strand displacement reactions that model temporal dynamics. **You might need to read the paper to fully understand this: https://arxiv.org/abs/2406.03456**\n",
    "\n",
    "In Alex's work he considers 2 types of chemical species:\n",
    "- Executive species ùëã - 'main' chemical species whose dynamics approximate the target system\n",
    "- Chemical perceptrons ùëå - auxiliary chemical species that change concentration rapidly and modulate the executive species concentrations\n",
    "- These species would have subscripts $i$ and $j$, respectively, referring to multiple species of Executive species $X_i$ and Chemical perceptrons $Y_j$\n",
    "\n",
    "In these chemical reaction networks, these executive species $X_i$ and chemical perceptrons $Y_j$ would interact **catalytically**, where one type catalyses the production or degradation of the other type, and vice versa. Each interaction has its own unique reaction rate coefficient.\n",
    "\n",
    "The CRN was designed specifically such that when the chemical perceptrons were at steady state, their concentration would model a 'perceptron' with a 'smoothed ReLU' activation function; they called this the chemical perceptron. \n",
    "\n",
    "What this means: \n",
    "- A perceptron is the original neurone of an artificial neural network that that takes the weighted mean of its inputs (and a bias), then applies a non-linear activation function. This enables the system to learn non-linear behaviours and dynamics.\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"Images/Perceptrons.png\" alt=\"Perceptrons\" width=\"50%\">\n",
    "</div>\n",
    "\n",
    "- The chemical perceptron had the same activity, where it would take the weighted mean of each executive species (where the weights corresponds to reaction rate coefficients of production/degradation of $X_i$ and the input is the $X_i$ concentrations), then apply a ReLU-like function on top of this (constructed by the reactions that $Y_j$ undergoes).\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"Images/CRN.png\" alt=\"CRN\" width=\"70%\">\n",
    "</div>\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"Images/ystar.png\" alt=\"ystar\" width=\"70%\">\n",
    "</div>\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"Images/smooth.png\" alt=\"smooth\" width=\"60%\">\n",
    "</div>\n",
    "\n",
    "This smoothed-RELU property of the chemical perceptrons when at steady state allows the system to learn temporal dynamics by using a separation of timescales. This is done by controlling a parameter $\\mu$ (where $0 \\le \\mu < 1$), which describes the relative speed of equilibration between executive species and chemical perceptrons:\n",
    "\n",
    "- Quasi-static approximation - first, we make the assumption that chemical perceptrons reach steady state instantaneously ($\\mu = 0$). \n",
    "\n",
    "    Intuitively, this means the perceptrons will instantly reach steady state concentration at each change of executive species concentration. The perceptrons always be at equilibrium concentration y*.\n",
    "\n",
    "    In this timescale, the executive species concentrations effectively feedback onto themselves, using the chemical perceptrons as an intermediary.\n",
    "\n",
    "    The RNCRN can act as a neural network, where the CRN parameters needed to produce the target dynamics can be trained using backpropagation. \n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"Images/QSA.png\" alt=\"QSA\" width=\"70%\">\n",
    "</div>\n",
    "\n",
    "- Dynamical approximation - next, we assume that the chemical perceptrons equilibrate quickly, but not infinitely quickly - but still much quicker than the executive species ($\\mu \\ll 1$).\n",
    "\n",
    "    Now, the idea is that we have a recurrent chemical reaction network, where the executive species and chemical perceptrons repeatedly modulate each other's concentrations such that the executive species dynamics follows that of the target system.\n",
    "\n",
    "    The smaller the value of $\\mu$, the theoretically closer the simulation will be to the target system, because this gets closer towards the neural net-like conditions that it was trained on.\n",
    "    \n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"Images/DA.png\" alt=\"DA\" width=\"70%\">\n",
    "</div>\n",
    "\n",
    "The key advantage of the RNCRNs (as opposed to other bio/chem dynamics-approximating ML systems) is it's experimental transferrability:\n",
    "- The trained parameters are reaction rate coefficients.\n",
    "- The initial conditions of the chemical perceptrons is arbitrary. This means fine-tuning of initial conditions is not necessary.\n",
    "\n",
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0533077d",
   "metadata": {},
   "source": [
    "### Adapting RNCRNs to spatiotemporal dynamics\n",
    "\n",
    "To learn spatiotemporal dynamics, the executive species would need to diffuse, thus a diffusion term is added to it's ODE to give a PDE of $X_i$. The diffusion constant ($D_X$) of $X_i$ is trainable.\n",
    "\n",
    "To maintain the same chemical perceptron steady state equation (y*), the chemical perceptrons are assumed to diffuse infinitely slowly, i.e. they are localised to a single grid-point in space.\n",
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6f0a49",
   "metadata": {},
   "source": [
    "### RNGRNs \n",
    "\n",
    "The RNGRNs rely on the idea that the expression of a gene and the diffusion of the corresponding gene product is on a much slower timescale than the binding dynamics that occur between a transcription factor and its complementary regulatory binding site. \n",
    "\n",
    "Now, our executive species are modelled as transcription factors $X_j$, while our chemical perceptrons are the gene regulatory sites (reffered hereon as promoters) $G_i$ of these transcription factors. We create a GRN of size $N$ where these transcription factors bind to each other's (and their own) promoter to up/downregulate gene expression.\n",
    "\n",
    "Each promoter can be in 3 possible states:\n",
    "$G_{i,\\text{free}}$, $G_{ij,A}$ or $G_{ij,R}$, which signify an unbound promoter, activated promoter or repressed promoter (no expression), respectively. The $j$ is added to $G_{ij,A}$ and $G_{ij,R}$ to denote the transcription factor bound to $G_i$.\n",
    "\n",
    "Total promoter count is normalised:\n",
    "$$1 = G_{i,\\text{tot}} = G_{i,\\text{free}} + \\sum_j G_{ij,A} + \\sum_j G_{ij,R}$$\n",
    "\n",
    "To be able to maintain the ability to learn non-linear dynamics, we propose that these transcription factors $X_j$ dimerise to be able to bind to a promoter region. This introduces cooperativity into the binding dynamics. To simplify the number of parameters present, we assume a tri-molecular interaction between 2 transcription factors of the same identity $X_j$ and a free promoter $G_{i,\\text{free}}$. **Each individual $i,j$ interaction can be either (but not both) a activation or repression interaction.**\n",
    " \n",
    "$$2x_j + G_{i,\\text{free}} \\rightleftharpoons^{k_{ij,A}^+}_{k_{ij,A}^-} G_{ij,A} \\qquad 2x_j + G_{i,\\text{free}} \\rightleftharpoons^{k_{ij,R}^+}_{k_{ij,R}^-} G_{ij,R}$$\n",
    "\n",
    "Therefore, the rate of change of activated/repressed promoters can be expressed as: \n",
    "$$\\frac{dG_{ij,A}}{dt} = k_{ij,A}^+ x_j^2 G_{i,\\text{free}} - k_{ij,A}^- G_{ij,A}$$\n",
    "$$\\frac{dG_{ij,R}}{dt} = k_{ij,R}^+ x_j^2 G_{i,\\text{free}} - k_{ij,R}^- G_{ij,R}$$\n",
    "\n",
    "Assuming $\\alpha$ represents strength of gene activation coefficient, the rate of change of executive species is: \n",
    "\n",
    "$$\\frac{\\partial x_i}{\\partial t} = \\beta_i + \\sum_j \\alpha_{ij} G_{ij,A} - \\delta_i x_i + D_{x_i} \\nabla^2 x_i$$\n",
    "\n",
    "where $\\beta_i$ the basal gene expression coefficient, $\\delta_i x_i$ is the rate of executive species degradation with its own degradation coefficient $\\delta_i$. The diffusion term is added at the end: $D_{x_i}$ is the diffusion coefficient, and $\\nabla^2 x_i$ represents spatial spreading.\n",
    "\n",
    "Note that an assumption we make is that $G_{i,\\text{tot}} \\ll x_j$, to be able to neglect $x_i$ sequestration.\n",
    "\n",
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca578e07",
   "metadata": {},
   "source": [
    "### Quasi-static approximation ($\\mu = 0$)\n",
    "\n",
    "Making the Quasi-steady state assumption that gene expression occurs on a much slower timescale than transcription factor-promoter binding $(\\frac{dG_{ij,A}}{dt}, \\frac{dG_{ij,R}}{dt}, \\mu \\approx 0)$: \n",
    "\n",
    "$$G_{i,A}^* = \\frac{\\sum_j K_{ij,A} x_j^2}{1 + \\sum_j K_{ij,A} x_j^2 + \\sum_j K_{ij,R} x_j^2}$$\n",
    "\n",
    "Where the rate constants have been combined into binding constants:\n",
    "\n",
    "$$K_{ij,A} = \\frac{k_{ij,A}^+}{k_{ij,A}^-} \\qquad K_{ij,R} = \\frac{k_{ij,R}^+}{k_{ij,R}^-}$$\n",
    "\n",
    "Note that the $G_{i,A}^*$ steady state is in the form of a hill function of $n=2$, letting us model a sigmoid activation function. \n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"Images/Hill.png\" alt=\"Hill\" width=\"60%\">\n",
    "</div>\n",
    "\n",
    "Thus at quasi-steady state, the change in executive species can be expressed as:\n",
    "\n",
    "$$\\frac{\\partial x_i}{\\partial t} = \\beta_i + \\left( \\frac{\\sum_j \\alpha_{ij} K_{ij,A} x_j^2}{1 + \\sum_j K_{ij,A} x_j^2 + \\sum_j K_{ij,R} x_j^2} \\right) - \\delta_i x_i + D_{x_i} \\nabla^2 x_i$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1d623f",
   "metadata": {},
   "source": [
    "### Dynamical approximation ($\\mu \\ll 1$).\n",
    "\n",
    "Without the QSS assumption, the base GRN can be expressed as: \n",
    "\n",
    "$$G_{i,\\text{free}} = 1 - \\sum_j G_{ij,A} - \\sum_j G_{ij,R}$$\n",
    "$$\\mu \\frac{dG_{ij,A}}{dt} = k_{ij,A}^+ x_j^2 G_{i,\\text{free}} - k_{ij,A}^- G_{ij,A}$$\n",
    "$$\\mu \\frac{dG_{ij,R}}{dt} = k_{ij,R}^+ x_j^2 G_{i,\\text{free}} - k_{ij,R}^- G_{ij,R}$$\n",
    "$$\\frac{\\partial x_i}{\\partial t} = \\beta_i + \\sum_j \\alpha_{ij} G_{ij,A} - \\delta_i x_i + D_{x_i} \\nabla^2 x_i$$\n",
    "\n",
    "Note the inclusion of $\\mu$, which describes the relative rate of equilibration of promoter binding relative to the executive species production."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cacc41b",
   "metadata": {},
   "source": [
    "# 1.Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e602423",
   "metadata": {},
   "source": [
    "## Import Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600ee32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Import libs\n",
    "import numpy as np\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from scipy.integrate import solve_ivp\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8675de56",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Use GPU\n",
    "print(\"Num GPUs Available: \", torch.cuda.device_count())\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc60bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Set random seed\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.set_default_dtype(torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa83a0cf",
   "metadata": {},
   "source": [
    "## Initialise solver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c97ad4",
   "metadata": {},
   "source": [
    "The solver bit is a bit complex. Solving common reaction-diffusion systems is already difficult, but when we train our RNGRN with tens of species and hundereds of parameters, the solving can become very unstable, especially in the reactions. \n",
    "\n",
    "Here, we try to use as robust of a solver as possible; a BDF1 (Backward Differentiation Formula of order 1) time integrator with Newton-Krylov linear solves. \n",
    "\n",
    "This section shouldn't need to be touched unless the solving is too slow and convergenvce thresholds need to be relaxed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc33855",
   "metadata": {},
   "source": [
    "### Generic functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92424e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Define laplacian operator\n",
    "def laplacian(field, dx):\n",
    "        # Assume periodic boundaries\n",
    "        lap = (torch.roll(field, 1, 0) + torch.roll(field, -1, 0) +\n",
    "               torch.roll(field, 1, 1) + torch.roll(field, -1, 1) - 4 * field) / (dx ** 2)\n",
    "        return lap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ccc284",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Define BDF1 time integrator with Newton-Krylov linear solves \n",
    "def bdf1_newton_krylov(X0, dt, Tmax, rhs_func, jvp_func=None, tol=1e-3, max_iter=10, gmres_max_iter=200, save_interval=1):\n",
    "    steps = int(Tmax / dt)\n",
    "    X = X0.clone()\n",
    "    trajectory = []\n",
    "\n",
    "    #Loop through time steps\n",
    "    for step in range(steps):\n",
    "\n",
    "        #Save trajectory at interval\n",
    "        if step % save_interval == 0:\n",
    "            trajectory.append(X.clone().cpu())\n",
    "\n",
    "        #Print progress at interval\n",
    "        print_interval = 1000\n",
    "        if print_interval and (step % print_interval) == 0:\n",
    "            print(f\"Simulation progress: step {step+1}/{steps}\")\n",
    "\n",
    "        # Initial guess for Newton's method\n",
    "        X_n = X.clone()\n",
    "        f_n = rhs_func(X_n)\n",
    "        X_guess = X_n + dt * f_n\n",
    "\n",
    "        # Prepare Jacobian Vector Product function\n",
    "        jvp_func = make_autograd_jvp(rhs_func)\n",
    "\n",
    "        # Newton iterations\n",
    "        for newton_iter in range(max_iter):\n",
    "            #Compute residual\n",
    "            f_val = rhs_func(X_guess)\n",
    "            G = X_guess - dt * f_val - X_n\n",
    "\n",
    "            #Check convergence\n",
    "            if torch.norm(G) < tol:\n",
    "                if step % print_interval == 0:  # print Newton convergence info at same interval\n",
    "                    print(f\"Newton converged in {newton_iter+1} iterations at step {step+1}\")\n",
    "                break\n",
    "\n",
    "            #Solve for Newton update using GMRES\n",
    "            A = lambda v: jvp_func(v, X_guess, dt)\n",
    "            b_gmres = -G\n",
    "            P = lambda v: v\n",
    "            w = gmres_torch(A, b_gmres, P=P, tol=tol, max_iter=gmres_max_iter)\n",
    "            X_guess += w\n",
    "        else:\n",
    "            print(f\"Newton did not converge at step {step+1} after {max_iter} iterations\")\n",
    "            \n",
    "        # Update solution\n",
    "        X = X_guess.clone()\n",
    "\n",
    "\n",
    "    return trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a02fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Generalized Minimal Residual (GMRES)\n",
    "def gmres_torch(A, b, P=None, tol=1e-6, max_iter=200):\n",
    "    #Initialise variables\n",
    "    if P is None:\n",
    "        P = lambda v: v\n",
    "    n = b.shape[0]\n",
    "    Q = torch.zeros((n, max_iter+1), dtype=b.dtype, device=b.device)\n",
    "    H = torch.zeros((max_iter+1, max_iter), dtype=b.dtype, device=b.device)\n",
    "\n",
    "    #GMRES iterations\n",
    "    x = torch.zeros_like(b)\n",
    "    r0 = b - A(x)\n",
    "    r = P(r0)\n",
    "    beta = torch.norm(r)\n",
    "    if beta == 0:\n",
    "        return x\n",
    "    Q[:, 0] = r / beta\n",
    "\n",
    "    #Arnoldi process\n",
    "    for k in range(max_iter):\n",
    "        q = P(A(Q[:, k]))\n",
    "        for i in range(k+1):\n",
    "            H[i, k] = torch.dot(Q[:, i], q)\n",
    "            q = q - H[i, k] * Q[:, i]\n",
    "        h = torch.norm(q)\n",
    "        H[k+1, k] = h\n",
    "        if h < 1e-12:\n",
    "            break\n",
    "        Q[:, k+1] = q / h\n",
    "\n",
    "        e1 = torch.zeros(k+2, dtype=b.dtype, device=b.device)\n",
    "        e1[0] = beta\n",
    "        H_small = H[:k+2, :k+1]\n",
    "        y, *_ = torch.linalg.lstsq(H_small, e1)\n",
    "        x = Q[:, :k+1] @ y\n",
    "\n",
    "        res_norm = torch.norm(P(b - A(x)))\n",
    "        if res_norm < tol:\n",
    "            break\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24d3af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###Autograd JVP factory and wrappers\n",
    "def make_autograd_jvp(rhs_func):\n",
    "    def jvp(v, X, dt):\n",
    "        X_req = X.detach().requires_grad_(True)\n",
    "        _, Jv = torch.autograd.functional.jvp(rhs_func, (X_req,), (v,), create_graph=False)\n",
    "        return v - dt * Jv\n",
    "    return jvp\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9806c843",
   "metadata": {},
   "source": [
    "### Set up RNGRN system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30aac37",
   "metadata": {},
   "source": [
    "Here, we define the 'full' RNGRN system  equations (no quasi-static approximation) for numerical simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9004e12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Define RNGRN equations\n",
    "def rhs_perceptron(X):\n",
    "    n = n_cells\n",
    "    n_nodes = n * n\n",
    "    nx = N * n_nodes  \n",
    "    nG_per_type = N * N * n_nodes  \n",
    "    nG_total = 2 * nG_per_type\n",
    "    \n",
    "    # Unpack X\n",
    "    x = X[:nx].view(N, n_nodes)  \n",
    "    G_A = X[nx:nx + nG_per_type].view(N, N, n_nodes) \n",
    "    G_R = X[nx + nG_per_type:].view(N, N, n_nodes) \n",
    "    \n",
    "    # Compute G_free for each i\n",
    "    G_free = 1.0 - G_A.sum(dim=1) - G_R.sum(dim=1)  \n",
    "    \n",
    "    # x dynamics with diffusion + reaction\n",
    "    xdot = torch.zeros_like(x)\n",
    "    for i in range(N):\n",
    "        lap_x = D[i] * laplacian(x[i].view(n, n), dx)\n",
    "        prod = beta[i] + (alpha[i].unsqueeze(1) * G_A[i]).sum(dim=0) - delta[i] * x[i]\n",
    "        xdot[i] = lap_x.flatten() + prod\n",
    "    \n",
    "    # G dynamics using trimolecular binding\n",
    "    Gdot_A = torch.zeros_like(G_A)\n",
    "    Gdot_R = torch.zeros_like(G_R)\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            Gdot_A[i, j] = (kA_plus[i, j] * x[j]**2 * G_free[i] - kA_minus[i, j] * G_A[i, j]) / mu\n",
    "            Gdot_R[i, j] = (kR_plus[i, j] * x[j]**2 * G_free[i] - kR_minus[i, j] * G_R[i, j]) / mu\n",
    "    \n",
    "    return torch.cat([xdot.flatten(), Gdot_A.flatten(), Gdot_R.flatten()])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3896e576",
   "metadata": {},
   "source": [
    "### Set up target system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de8e848",
   "metadata": {},
   "source": [
    "**Target system info**\n",
    "\n",
    "Using the most robust non-competitive 3-node 2 diffuser model from Scholes 2019. 3 nodes will give the RNGRN model greater flexibility. \n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"Images/Scholes.png\" alt=\"Scholes\" width=\"50%\">\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3f9fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define Target system equations\n",
    "def rhs_target(X):\n",
    "    n = n_cells\n",
    "    n_nodes = n * n\n",
    "    A = X[0:n_nodes].view(n, n)\n",
    "    B = X[n_nodes:2 * n_nodes].view(n, n)\n",
    "    C = X[2 * n_nodes:].view(n, n)\n",
    "\n",
    "    lap_A = laplacian(A, dx)\n",
    "    lap_B = laplacian(B, dx)\n",
    "    lap_C = laplacian(C, dx)\n",
    "\n",
    "    # Parameters \n",
    "    k11 = 3.1623\n",
    "    k21 = 100.0\n",
    "    k31 = 100.0\n",
    "    k12 = 3.1623\n",
    "    k22 = 0.0\n",
    "    k32 = 3.1623\n",
    "    k13 = 0.0\n",
    "    k23 = 3.1623\n",
    "    k33 = 0.1\n",
    "\n",
    "    mu1 = 0.01\n",
    "    mu2 = 0.01\n",
    "    mu3 = 0.01\n",
    "\n",
    "    d1 = 1.0\n",
    "    d2 = 0.01\n",
    "    d3 = 0.0\n",
    "\n",
    "    n_hill = 4\n",
    "\n",
    "    V1 = V2 = V3 = 100.0\n",
    "    b1 = b2 = b3 = 0.1\n",
    "\n",
    "    # Numerics\n",
    "    eps = 1e-8\n",
    "\n",
    "    # Hill functions\n",
    "    def hill_act(x, K):\n",
    "        if K == 0.0:\n",
    "            return torch.ones_like(x)\n",
    "        x = torch.clamp(x, min=eps)\n",
    "        return 1.0 / (1.0 + (K / x) ** n_hill)\n",
    "\n",
    "    def hill_inh(x, K):\n",
    "        if K == 0.0:\n",
    "            return torch.ones_like(x)\n",
    "        x = torch.clamp(x, min=eps)\n",
    "        return 1.0 / (1.0 + (x / K) ** n_hill)\n",
    "\n",
    "    prod_A = V1 * hill_act(A, k11) * hill_inh(B, k12)                 \n",
    "    prod_B = V2 * hill_act(A, k21) * hill_inh(C, k23)                   \n",
    "    prod_C = V3 * hill_inh(A, k31) * hill_inh(B, k32) * hill_act(C, k33)\n",
    "\n",
    "    dA = d1 * lap_A + prod_A + b1 - mu1 * A\n",
    "    dB = d2 * lap_B + prod_B + b2 - mu2 * B\n",
    "    dC = d3 * lap_C + prod_C + b3 - mu3 * C\n",
    "\n",
    "    diffs = [dA, dB, dC]\n",
    "    return torch.cat([d.flatten() for d in diffs])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e07184",
   "metadata": {},
   "source": [
    "# 2.Quasi-Static Approximation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64959458",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40210046",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Set domain params\n",
    "n_cells = 10\n",
    "L = torch.tensor(5.0, dtype=torch.float32, device=device)\n",
    "dx = float(L) / float(n_cells)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123fe1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Set target simulation params\n",
    "dt = torch.tensor(0.01, dtype=torch.float32, device=device)\n",
    "Tmax = torch.tensor(500.0, dtype=torch.float32, device=device)\n",
    "steps = int(Tmax / dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6084e5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Set intitial conditions\n",
    "n_species = 3\n",
    "init_fields = []\n",
    "for _ in range(n_species):\n",
    "    field = torch.clamp(1.0 + 0.1 * torch.randn(n_cells, n_cells, dtype=torch.float32, device=device), min=0.001)\n",
    "    init_fields.append(field)\n",
    "\n",
    "X0 = torch.cat([f.flatten() for f in init_fields]).to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574972ec",
   "metadata": {},
   "source": [
    "## Generate training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a254cb",
   "metadata": {},
   "source": [
    "To generate training data, we simulate the target system. It's simulated in a 10x10 grid for simplicity - we would generate too much data if we simulated a larger grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c870a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Simulate target system \n",
    "trajectory = bdf1_newton_krylov(X0, dt, Tmax, rhs_target, jvp_func=None, save_interval=1)\n",
    "print(f\"Simulation completed with {len(trajectory)} time steps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8591a674",
   "metadata": {},
   "source": [
    "Calculate laplacian values and instantaneous rates from simulated trajectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a3564c",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Generate training data\n",
    "#Prepare storage\n",
    "field_trajectory = []\n",
    "lap_trajectory = []\n",
    "dx_dt_trajectory = []\n",
    "\n",
    "n_nodes = n_cells * n_cells\n",
    "n_species = 3\n",
    "subsample_factor = 1 \n",
    "\n",
    "#Loop through each time step \n",
    "for i in range(0, len(trajectory), subsample_factor):\n",
    "    X = trajectory[i].to(device) \n",
    "    fields = [X[j * n_nodes:(j + 1) * n_nodes].view(n_cells, n_cells) for j in range(n_species)]\n",
    "    laps = [laplacian(f, dx) for f in fields]\n",
    "\n",
    "    dX = rhs_target(X)\n",
    "    d_fields = [dX[j * n_nodes:(j + 1) * n_nodes].view(n_cells, n_cells) for j in range(n_species)]\n",
    "\n",
    "    field_trajectory.append(torch.stack([f.clone() for f in fields]))\n",
    "    lap_trajectory.append(torch.stack(laps))\n",
    "    dx_dt_trajectory.append(torch.stack(d_fields))\n",
    "\n",
    "#Generate feature and target tensors\n",
    "fields_stacked = torch.stack(field_trajectory)  \n",
    "laps_stacked = torch.stack(lap_trajectory)      \n",
    "feature_tensor = torch.cat([fields_stacked, laps_stacked], dim=1)  \n",
    "\n",
    "dx_dt_stacked = torch.stack(dx_dt_trajectory)  \n",
    "target_tensor = dx_dt_stacked\n",
    "\n",
    "print(f\"Feature tensor shape: {feature_tensor.shape}\")\n",
    "print(f\"Target tensor shape: {target_tensor.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79aaac9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Prepare training data\n",
    "#Shuffle timepoints\n",
    "perm = torch.randperm(feature_tensor.size(0))\n",
    "feature_tensor = feature_tensor[perm]\n",
    "target_tensor = target_tensor[perm]\n",
    "\n",
    "#Split dataset by validation split \n",
    "val_split = 0.2\n",
    "T = feature_tensor.size(0)\n",
    "train_size = int((1 - val_split) * T)\n",
    "train_features = feature_tensor[:train_size]\n",
    "train_targets = target_tensor[:train_size]\n",
    "val_features = feature_tensor[train_size:]\n",
    "val_targets = target_tensor[train_size:]\n",
    "\n",
    "#Split into batches for training \n",
    "batch_size = 32\n",
    "train_dataset = TensorDataset(train_features, train_targets)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataset = TensorDataset(val_features, val_targets)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "print(f\"Val dataset size: {len(val_dataset)}\")\n",
    "print(f\"Batch size: {batch_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec8cb85",
   "metadata": {},
   "source": [
    "## Train RNGRN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f4ed75",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Model size/number of nodes\n",
    "N = 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a00fe41",
   "metadata": {},
   "source": [
    "Here, we set up a simple feedforward neural network with the 'reduced' (quasi-static approximated) RNGRN system. \n",
    "Some notable features:\n",
    "- Because we are modelling GRNs, no parameter can be negative. Hence the softplus parameterisation of everything.\n",
    "- We want to ensure every interaction is **either** an activation or repression interaction, thus we have this logic gated training of the KA and KR constants where:\n",
    "\n",
    "$$s_{ij} \\ge 0$$\n",
    "$$g_{ij} \\in [0, 1]$$\n",
    "$$K_{ij,A} = s_{ij} g_{ij}$$\n",
    "$$K_{ij,R} = s_{ij} (1 - g_{ij})$$\n",
    "\n",
    "$s$ represents the interaction strength, irrespective of activation or repression interaction.\n",
    "\n",
    "$g$ represents the gating, and will be either 0 (repression) or 1 (activation). Thus it is sigmoid parameterised. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c25713e",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Custom Gated Competitive Promoter layer\n",
    "class GatedCompetitivePromoter(nn.Module):\n",
    "    #Initialize parameters\n",
    "    def __init__(self, N):\n",
    "        super().__init__()\n",
    "        self.N = N\n",
    "\n",
    "        # Parameterise to ensure positivity\n",
    "        self.theta_s = nn.Parameter(torch.normal(0.5, 0.1, (N, N), dtype=torch.float32))\n",
    "        self.theta_g = nn.Parameter(torch.full((N, N), -0.5, dtype=torch.float32))\n",
    "        self.theta_beta = nn.Parameter(torch.full((N,), -1.0, dtype=torch.float32))\n",
    "        self.theta_alpha = nn.Parameter(torch.full((N, N), 0.5, dtype=torch.float32))\n",
    "        self.theta_delta = nn.Parameter(torch.full((N,), 0.5, dtype=torch.float32))\n",
    "\n",
    "        # Set trainability for D\n",
    "        self.trainable_D = [True, True, False]\n",
    "        assert len(self.trainable_D) == self.N, \"trainable_D must have length N\"\n",
    "        trainable_mask = torch.tensor(self.trainable_D, dtype=torch.bool)\n",
    "        self.theta_D = nn.Parameter(torch.where(trainable_mask, 0.5, -100.0))\n",
    "\n",
    "    #RNGRN system with diffusion\n",
    "    def forward(self, x):\n",
    "        batch, channels, H, W = x.shape\n",
    "        assert channels == 2 * self.N, f\"Expected {2 * self.N} channels, got {channels}\"\n",
    "\n",
    "        x_state = x[:, :self.N]       \n",
    "        lap_x = x[:, self.N:]         \n",
    "\n",
    "        x_flat = x_state.permute(0, 2, 3, 1).reshape(-1, self.N) \n",
    "        x2_flat = torch.square(x_flat)\n",
    "\n",
    "        self.s = torch.nn.functional.softplus(self.theta_s)\n",
    "        self.g = torch.sigmoid(self.theta_g)\n",
    "        KA = self.s * self.g\n",
    "        KR = self.s * (1 - self.g)\n",
    "\n",
    "        sum_A = torch.matmul(x2_flat, KA.T)  \n",
    "        sum_R = torch.matmul(x2_flat, KR.T) \n",
    "        denom = 1 + sum_A + sum_R + 1e-8\n",
    "\n",
    "        GA_matrix = (x2_flat[:, None, :] * KA[None, :, :]) / denom[:, :, None]  \n",
    "\n",
    "        alpha = torch.nn.functional.softplus(self.theta_alpha)\n",
    "        delta = torch.nn.functional.softplus(self.theta_delta)\n",
    "        beta = torch.nn.functional.softplus(self.theta_beta)\n",
    "        D = torch.nn.functional.softplus(self.theta_D)\n",
    "\n",
    "        activation = (GA_matrix * alpha[None, :, :]).sum(dim=2)  \n",
    "        xdot_reac = beta + activation - delta * x_flat           \n",
    "\n",
    "        xdot_reac = xdot_reac.view(batch, H, W, self.N).permute(0, 3, 1, 2) \n",
    "\n",
    "        xdot = D.view(1, -1, 1, 1) * lap_x + xdot_reac\n",
    "        return xdot\n",
    "\n",
    "    #Return trained params \n",
    "    def mapped_params(self):\n",
    "        s = torch.nn.functional.softplus(self.theta_s).detach().cpu().numpy()\n",
    "        g = torch.sigmoid(self.theta_g).detach().cpu().numpy()\n",
    "        KA = s * g\n",
    "        KR = s * (1 - g)\n",
    "        alpha = torch.nn.functional.softplus(self.theta_alpha).detach().cpu().numpy()\n",
    "        delta = torch.nn.functional.softplus(self.theta_delta).detach().cpu().numpy()\n",
    "        beta  = torch.nn.functional.softplus(self.theta_beta).detach().cpu().numpy()\n",
    "        D = torch.nn.functional.softplus(self.theta_D).detach().cpu().numpy()\n",
    "\n",
    "        return s, g, KA, KR, alpha, delta, beta, D\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99516edc",
   "metadata": {},
   "source": [
    "This GateProjector function nudges the gating $g$ towards 0 or 1 at the end of every epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c69197",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Gate Projector - ensure interactions are activation OR repression\n",
    "class GateProjector:\n",
    "    def __init__(self, layer_name=\"GatedCompetitivePromoter\", thr=0.1, hard_K=1.0):\n",
    "        self.layer_name = layer_name\n",
    "        self.thr = float(thr)\n",
    "        self.hard_K = float(hard_K)\n",
    "    \n",
    "    def apply(self, model):\n",
    "        layer = model\n",
    "        g = torch.sigmoid(layer.theta_g)  \n",
    "        low = g < self.thr\n",
    "        high = g > (1.0 - self.thr)\n",
    "        theta = layer.theta_g.clone()  \n",
    "        theta = torch.where(low, -self.hard_K * torch.ones_like(theta), theta)\n",
    "        theta = torch.where(high, self.hard_K * torch.ones_like(theta), theta)\n",
    "        layer.theta_g.data.copy_(theta) \n",
    "\n",
    "projector = GateProjector(layer_name=\"GatedCompetitivePromoter\", thr=0.5, hard_K=100.0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234714e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Set training hyperparameters\n",
    "num_epochs = 200\n",
    "LR = 1e-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3942e9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Build model\n",
    "model = GatedCompetitivePromoter(N=N).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d270db",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss_sum = 0.0\n",
    "    train_n = 0\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        x_batch = x_batch.to(device); y_batch = y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(x_batch)\n",
    "        loss = criterion(pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        bs = x_batch.size(0)\n",
    "        train_loss_sum += loss.item() * bs\n",
    "        train_n += bs\n",
    "    train_loss = train_loss_sum / train_n\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss_sum = 0.0\n",
    "    val_n = 0\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in val_loader:\n",
    "            x_batch = x_batch.to(device); y_batch = y_batch.to(device)\n",
    "            pred = model(x_batch)\n",
    "            loss = criterion(pred, y_batch)\n",
    "            bs = x_batch.size(0)\n",
    "            val_loss_sum += loss.item() * bs\n",
    "            val_n += bs\n",
    "    val_loss = val_loss_sum / val_n\n",
    "    \n",
    "    # Apply gate projection\n",
    "    projector.apply(model)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a110676e",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Pull learned parameters\n",
    "model_params = model.mapped_params()\n",
    "s, g, KA_mat, KR_mat, alpha, delta, beta, D = model_params  \n",
    "\n",
    "print(\"s:\"); print(s)\n",
    "print(\"g:\"); print(g)\n",
    "print(\"KA_mat:\"); print(KA_mat)\n",
    "print(\"\\nKR_mat:\"); print(KR_mat)\n",
    "print(f\"\\nalpha: {alpha}\")\n",
    "print(f\"delta: {delta}\")\n",
    "print(f\"beta: {beta}\")\n",
    "print(f\"D: {D}\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a9e235",
   "metadata": {},
   "source": [
    "# 3.Dynamical Approximation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465795db",
   "metadata": {},
   "source": [
    "## Prepare full RNGRN system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff10d60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull learned parameters and convert to torch tensors\n",
    "KA_mat = torch.tensor(KA_mat, dtype=torch.float32, device=device)\n",
    "KR_mat = torch.tensor(KR_mat, dtype=torch.float32, device=device)\n",
    "alpha = torch.tensor(alpha, dtype=torch.float32, device=device)\n",
    "delta = torch.tensor(delta, dtype=torch.float32, device=device)\n",
    "beta = torch.tensor(beta, dtype=torch.float32, device=device)\n",
    "D = torch.tensor(D, dtype=torch.float32, device=device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c95e9d7",
   "metadata": {},
   "source": [
    "To prevent simulation instability and to make the predicted model more simple, we prune the interactions that are very weak, where KA or KR is less than 0.00001.\n",
    "\n",
    "Because the 'reduced' RNGRN model has binding constants KA and KR, while the 'full' model requires rate constants (kA+, kA-, kR+, kR-), we can assign any pair of k+ k- that fit the binding constant K. So we set k+ = 1 and k- = 1/K."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4eacdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Set up RNGRN simulation params\n",
    "# Define minimum KA and KR\n",
    "min_K = 1e-5\n",
    "KA_mat = torch.where(KA_mat < min_K, torch.zeros_like(KA_mat), KA_mat)\n",
    "KR_mat = torch.where(KR_mat < min_K, torch.zeros_like(KR_mat), KR_mat)\n",
    "\n",
    "# Precompute k_plus and k_minus matrices\n",
    "mask_A = KA_mat != 0\n",
    "mask_R = KR_mat != 0\n",
    "kA_plus  = torch.where(mask_A, torch.ones_like(KA_mat), torch.zeros_like(KA_mat))\n",
    "kA_minus = torch.where(mask_A, 1.0 / KA_mat,          torch.zeros_like(KA_mat))\n",
    "kR_plus  = torch.where(mask_R, torch.ones_like(KR_mat), torch.zeros_like(KR_mat))\n",
    "kR_minus = torch.where(mask_R, 1.0 / KR_mat,           torch.zeros_like(KR_mat))\n",
    "\n",
    "print (\"kA_plus:\"); print(kA_plus)\n",
    "print (\"\\nkA_minus:\"); print(kA_minus)\n",
    "print (\"\\nkR_plus:\"); print(kR_plus)\n",
    "print (\"\\nkR_minus:\"); print(kR_minus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99de6b73",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecf1b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define model size\n",
    "N = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8da7ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Define mu parameter for perceptron model\n",
    "mu = torch.tensor(0.01, dtype=torch.float32, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28688b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Set domain params\n",
    "n_cells = 100\n",
    "L = torch.tensor(50.0, dtype=torch.float32, device=device)\n",
    "dx = L / float(n_cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522c9d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Set initial conditons\n",
    "init_fields = []\n",
    "for _ in range(N):\n",
    "    field = torch.clamp(1.0 + 0.1 * torch.randn(n_cells, n_cells, dtype=torch.float32, device=device), min=0.001)\n",
    "    init_fields.append(field)\n",
    "\n",
    "#Set up target initial condition vector\n",
    "X0 = torch.cat([f.flatten() for f in init_fields]).to(device)\n",
    "\n",
    "#Set up perceptron initial condition vector\n",
    "n_nodes = n_cells * n_cells\n",
    "nx = N * n_nodes\n",
    "nG_per_type = N * N * n_nodes\n",
    "# init x from first N species of target IC and zero promoters\n",
    "x_init = torch.stack([f.flatten() for f in init_fields])[:N].view(N, n_nodes)\n",
    "G_A0 = torch.zeros((N, N, n_nodes), dtype=torch.float32, device=device)\n",
    "G_R0 = torch.zeros_like(G_A0)\n",
    "X0_perceptron = torch.cat([x_init.flatten(), G_A0.flatten(), G_R0.flatten()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f86a0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Set simulation params\n",
    "dt = torch.tensor(0.001, dtype=torch.float32, device=device)\n",
    "Tmax = torch.tensor(500.0, dtype=torch.float32, device=device)\n",
    "steps = int(Tmax / dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c07173",
   "metadata": {},
   "source": [
    "## Simulate trained RNGRN system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2953b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Simulation with trained RNGRN system\n",
    "trajectory_rngrn = bdf1_newton_krylov(X0_perceptron, dt, Tmax, rhs_perceptron, jvp_func=None, tol=1e-1, max_iter=10, gmres_max_iter=100, save_interval=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7d7338",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Generate sample of simulation\n",
    "#Sample frames \n",
    "num_snaps = len(trajectory_rngrn)\n",
    "fractions = np.array([0.0, 0.25, 0.5, 0.75, 1.0])\n",
    "idxs = np.clip(np.round(fractions * (num_snaps - 1)).astype(int), 0, num_snaps - 1)\n",
    "\n",
    "#Time per saved snap\n",
    "dt_float = float(dt.item()) if hasattr(dt, \"item\") else float(dt)\n",
    "times = idxs * dt_float\n",
    "\n",
    "#Extract u frames \n",
    "u_frames = [trajectory_rngrn[i][:n_cells*n_cells].view(n_cells, n_cells).cpu().numpy() for i in idxs]\n",
    "\n",
    "#Consistent colour scale \n",
    "vmin = min(frame.min() for frame in u_frames)\n",
    "vmax = max(frame.max() for frame in u_frames)\n",
    "\n",
    "#Plot u snapshots\n",
    "fig, axes = plt.subplots(1, len(u_frames), figsize=(3*len(u_frames), 3))\n",
    "for ax, fr, t in zip(axes, u_frames, times):\n",
    "    ax.imshow(fr, origin='lower', interpolation='nearest', vmin=vmin, vmax=vmax)\n",
    "    ax.set_title(f\"t = {t:.2f}\")\n",
    "    ax.axis('off')\n",
    "fig.suptitle('RNGRN system (u)', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0068324",
   "metadata": {},
   "source": [
    "## Simulate target system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfcb4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Simulation with target system\n",
    "trajectory_target = bdf1_newton_krylov(X0, dt, Tmax, rhs_target, jvp_func=None, tol=1e-2, max_iter=5, gmres_max_iter=200, save_interval=100)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d23fc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Generate sample of simulation\n",
    "#Sample frames \n",
    "num_snaps = len(trajectory_target)\n",
    "fractions = np.array([0.0, 0.25, 0.5, 0.75, 1.0])\n",
    "idxs = np.clip(np.round(fractions * (num_snaps - 1)).astype(int), 0, num_snaps - 1)\n",
    "\n",
    "#Time per saved snap\n",
    "dt_float = float(dt.item()) if hasattr(dt, \"item\") else float(dt)\n",
    "times = idxs * dt_float\n",
    "\n",
    "#Extract u frames \n",
    "u_frames = [trajectory_target[i][:n_cells*n_cells].view(n_cells, n_cells).cpu().numpy() for i in idxs]\n",
    "\n",
    "#Consistent colour scale \n",
    "vmin = min(frame.min() for frame in u_frames)\n",
    "vmax = max(frame.max() for frame in u_frames)\n",
    "\n",
    "#Plot u snapshots\n",
    "fig, axes = plt.subplots(1, len(u_frames), figsize=(3*len(u_frames), 3))\n",
    "for ax, fr, t in zip(axes, u_frames, times):\n",
    "    ax.imshow(fr, origin='lower', interpolation='nearest', vmin=vmin, vmax=vmax)\n",
    "    ax.set_title(f\"t = {t:.2f}\")\n",
    "    ax.axis('off')\n",
    "fig.suptitle('Target system (A)', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf841b4f",
   "metadata": {},
   "source": [
    "## Compare simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e46510f",
   "metadata": {},
   "source": [
    "We can compare the MSE difference between the simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694916c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Calculate MSE over time\n",
    "T = min(len(trajectory_target), len(trajectory_rngrn))\n",
    "\n",
    "n_nodes = n_cells * n_cells\n",
    "mse_u_x1 = []\n",
    "\n",
    "for i in range(T):\n",
    "    u_t = trajectory_target[i][:n_nodes].cpu().float()         \n",
    "    x_block = trajectory_rngrn[i][:N * n_nodes].cpu().float()  \n",
    "    x1 = x_block[:n_nodes]                                     \n",
    "    mse_u_x1.append(float(((u_t - x1) ** 2).mean().item()))\n",
    "\n",
    "mse_u_x1 = np.array(mse_u_x1)\n",
    "overall_mse = mse_u_x1.mean()\n",
    "print(f\"Overall MSE between target A and RNGRN x1 over {T} timepoints: {overall_mse:.6e}\")\n",
    "\n",
    "dt_float = float(dt.item()) if hasattr(dt, \"item\") else float(dt)\n",
    "times = np.arange(T) * dt_float\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.semilogy(times, mse_u_x1, label=\"MSE(A vs x1)\")\n",
    "plt.xlabel(\"time\")\n",
    "plt.ylabel(\"MSE (log scale)\")\n",
    "plt.title(\"MSE between target A and RNGRN x1 over time\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
